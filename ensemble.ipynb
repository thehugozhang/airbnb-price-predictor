{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e395ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Silence warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Team data set.\n",
    "df = pd.read_csv('Airbnb-CLEANED.csv') #, dtype={'id': 'int', 'NAME': 'str', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87f6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['number of reviews', 'review rate number', 'price', 'Construction year']]\n",
    "\n",
    "for index, row in df_subset.iterrows():\n",
    "    if (str(row['review rate number']) == 'nan'):\n",
    "        df_subset = df_subset.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a3de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "construction_year_scaler = min_max_scaler.fit(df_subset['Construction year'].values.reshape(-1, 1))\n",
    "construction_year_scaled = construction_year_scaler.transform(df_subset['Construction year'].values.reshape(-1, 1))\n",
    "df_subset[\"construction year scaled\"] = construction_year_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dbe21",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934df146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into tertiles.\n",
    "tertile = df_subset['price'].quantile([.33, .66])\n",
    "tertiles = [432, 808]\n",
    "\n",
    "def get_tertile(price):\n",
    "    if (price < tertiles[0]):\n",
    "        return 1\n",
    "    if (price < tertiles[1]):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "tertiles_col = []\n",
    "for index, row in df_subset[['price']].iterrows():\n",
    "    tertiles_col.append(get_tertile(row['price']))\n",
    "    \n",
    "df_subset['price_tertile'] = tertiles_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ea2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "quintile = df_subset['number of reviews'].quantile([.2, .4, .6, .8])\n",
    "quintiles = [1, 4, 13, 41]\n",
    "def get_quintile(price):\n",
    "    if (price <= quintiles[0]):\n",
    "        return 1\n",
    "    if (price <= quintiles[1]):\n",
    "        return 2\n",
    "    if (price <= quintiles[2]):\n",
    "        return 3\n",
    "    if (price <= quintiles[3]):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "quintiles_col = []\n",
    "for index, row in df_subset[['number of reviews']].iterrows():\n",
    "    quintiles_col.append(get_quintile(row['number of reviews']))\n",
    "    \n",
    "df_subset['reviews_quintile'] = quintiles_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82dc81",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556909fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35226928131001717\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "decision_tree_x = df_subset[['reviews_quintile', 'review rate number', 'construction year scaled']].values\n",
    "decision_tree_y = df_subset['price_tertile'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(decision_tree_x, decision_tree_y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dc34d",
   "metadata": {},
   "source": [
    "#### Attempted tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17884d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0          0.051133      0.001436         0.009811        0.000698   \n",
      "1          0.051619      0.001138         0.010306        0.000406   \n",
      "2          0.046007      0.001924         0.010542        0.000654   \n",
      "3          0.042759      0.001241         0.009138        0.001128   \n",
      "4          0.038657      0.007406         0.009766        0.001486   \n",
      "...             ...           ...              ...             ...   \n",
      "2911       0.141166      0.009385         0.019916        0.003539   \n",
      "2912       0.142994      0.010928         0.015612        0.001053   \n",
      "2913       0.121852      0.004598         0.015396        0.001182   \n",
      "2914       0.119337      0.004920         0.014599        0.001633   \n",
      "2915       0.103215      0.009092         0.012810        0.001549   \n",
      "\n",
      "     param_criterion param_max_depth param_min_samples_leaf  \\\n",
      "0               gini               2                      2   \n",
      "1               gini               2                      2   \n",
      "2               gini               2                      2   \n",
      "3               gini               2                      2   \n",
      "4               gini               2                      2   \n",
      "...              ...             ...                    ...   \n",
      "2911         entropy              18                     19   \n",
      "2912         entropy              18                     19   \n",
      "2913         entropy              18                     19   \n",
      "2914         entropy              18                     19   \n",
      "2915         entropy              18                     19   \n",
      "\n",
      "     param_min_samples_split  \\\n",
      "0                          2   \n",
      "1                          4   \n",
      "2                          6   \n",
      "3                          8   \n",
      "4                         10   \n",
      "...                      ...   \n",
      "2911                      10   \n",
      "2912                      12   \n",
      "2913                      14   \n",
      "2914                      16   \n",
      "2915                      18   \n",
      "\n",
      "                                                 params  split0_test_score  \\\n",
      "0     {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.333776   \n",
      "1     {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.333776   \n",
      "2     {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.333776   \n",
      "3     {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.333776   \n",
      "4     {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.333776   \n",
      "...                                                 ...                ...   \n",
      "2911  {'criterion': 'entropy', 'max_depth': 18, 'min...           0.345274   \n",
      "2912  {'criterion': 'entropy', 'max_depth': 18, 'min...           0.345274   \n",
      "2913  {'criterion': 'entropy', 'max_depth': 18, 'min...           0.345274   \n",
      "2914  {'criterion': 'entropy', 'max_depth': 18, 'min...           0.345274   \n",
      "2915  {'criterion': 'entropy', 'max_depth': 18, 'min...           0.345274   \n",
      "\n",
      "      split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0              0.341041           0.341041           0.341294   \n",
      "1              0.341041           0.341041           0.341294   \n",
      "2              0.341041           0.341041           0.341294   \n",
      "3              0.341041           0.341041           0.341294   \n",
      "4              0.341041           0.341041           0.341294   \n",
      "...                 ...                ...                ...   \n",
      "2911           0.344895           0.347865           0.352793   \n",
      "2912           0.344895           0.347865           0.352793   \n",
      "2913           0.344895           0.347865           0.352793   \n",
      "2914           0.344895           0.347865           0.352793   \n",
      "2915           0.344895           0.347865           0.352793   \n",
      "\n",
      "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0              0.335545         0.338539        0.003218             2269  \n",
      "1              0.335545         0.338539        0.003218             2269  \n",
      "2              0.335545         0.338539        0.003218             2269  \n",
      "3              0.335545         0.338539        0.003218             2269  \n",
      "4              0.335545         0.338539        0.003218             2269  \n",
      "...                 ...              ...             ...              ...  \n",
      "2911           0.347106         0.347587        0.002828              649  \n",
      "2912           0.347106         0.347587        0.002828              649  \n",
      "2913           0.347106         0.347587        0.002828              649  \n",
      "2914           0.347106         0.347587        0.002828              649  \n",
      "2915           0.347106         0.347587        0.002828              649  \n",
      "\n",
      "[2916 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "tree_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(2, 20, 2)),\n",
    "    'min_samples_split': list(range(2, 20, 2)),\n",
    "    'min_samples_leaf': list(range(2, 20)),\n",
    "}\n",
    "clf = GridSearchCV(tree.DecisionTreeClassifier(), param_grid = tree_params, cv = 5, n_jobs=10, scoring='f1_micro')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "print(\"Results:\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33df926",
   "metadata": {},
   "source": [
    "### Voting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e90c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 1 results: 0.35060143535833416\n",
      "\n",
      "Voting Classifier 2 results: 0.3521176589507733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf1 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf4 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf5 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf6 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf7 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf8 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf9 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf10 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "clf11 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features='sqrt')\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('decision tree 1', clf1),\n",
    "    ('decision tree 2', clf2),\n",
    "    ('decision tree 3', clf3),\n",
    "    ('decision tree 4', clf4),\n",
    "    ('decision tree 5', clf5),\n",
    "    ('decision tree 6', clf6),\n",
    "    ('decision tree 7', clf7),\n",
    "    ('decision tree 8', clf8),\n",
    "    ('decision tree 9', clf9),\n",
    "    ('decision tree 10', clf10),\n",
    "    ('decision tree 11', clf11),\n",
    "], voting='hard')\n",
    "\n",
    "rf_clf1 = RandomForestClassifier()\n",
    "rf_clf2 = RandomForestClassifier()\n",
    "rf_clf3 = RandomForestClassifier()\n",
    "rf_clf4 = RandomForestClassifier()\n",
    "rf_clf5 = RandomForestClassifier()\n",
    "rf_clf6 = RandomForestClassifier()\n",
    "rf_clf7 = RandomForestClassifier()\n",
    "rf_clf8 = RandomForestClassifier()\n",
    "rf_clf9 = RandomForestClassifier()\n",
    "rf_clf10 = RandomForestClassifier()\n",
    "rf_clf11 = RandomForestClassifier()\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "    ('random forest 1', rf_clf1),\n",
    "    ('random forest 2', rf_clf2),\n",
    "    ('random forest 3', rf_clf3),\n",
    "    ('random forest 4', rf_clf4),\n",
    "    ('random forest 5', rf_clf5),\n",
    "    ('random forest 6', rf_clf6),\n",
    "    ('random forest 7', rf_clf7),\n",
    "    ('random forest 8', rf_clf8),\n",
    "    ('random forest 9', rf_clf9),\n",
    "    ('random forest 10', rf_clf10),\n",
    "    ('random forest 11', rf_clf11),\n",
    "], voting='hard')\n",
    "\n",
    "eclf1.fit(X_train, y_train)\n",
    "print(\"Voting Classifier 1 results:\", eclf1.score(X_test, y_test))\n",
    "\n",
    "eclf2.fit(X_train, y_train)\n",
    "print(\"\\nVoting Classifier 2 results:\", eclf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d213a30",
   "metadata": {},
   "source": [
    "### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ecc22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BaggingClassifier accuracy: 0.354240371980188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "eclf1 = BaggingClassifier(base_estimator=clf1)\n",
    "\n",
    "param_combos = {'max_features': np.arange(0.1, 1.0, 0.1)}\n",
    "\n",
    "clf1 = GridSearchCV(eclf1, param_grid = param_combos, cv = 5, n_jobs=10, scoring='f1_micro')\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "clf2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=3, min_samples_split=64, max_features=0.6)\n",
    "eclf2 = BaggingClassifier(base_estimator=clf2)\n",
    "eclf2.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBaggingClassifier accuracy:\", eclf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011219f",
   "metadata": {},
   "source": [
    "### Packaged ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc04727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Accuracy: 0.3481754776104316\n",
      "ABC Accuracy: 0.3411503082987971\n",
      "RFC Accuracy: 0.35333063782472457\n",
      "ETC Accuracy: 0.35226928131001717\n",
      "HGBC Accuracy: 0.3534317193975538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "models = {'GBC':GradientBoostingClassifier(), 'ABC':AdaBoostClassifier(), 'RFC':RandomForestClassifier(), 'ETC':ExtraTreesClassifier(), 'HGBC': HistGradientBoostingClassifier() }\n",
    "for k in models.keys():\n",
    "    models[k].fit(X_train, y_train)\n",
    "    print(k, \"Accuracy:\", models[k].score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
